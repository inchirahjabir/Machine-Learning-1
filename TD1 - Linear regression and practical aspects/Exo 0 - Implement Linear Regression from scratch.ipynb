{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Implementing Linear Regression from Scratch with California Housing Dataset </b>\n",
    "\n",
    "Objective:\n",
    "This exercise aims to provide a hands-on experience in implementing linear regression from scratch using the California housing dataset. You will gain a deeper understanding of the inner workings of linear regression, including the concepts of cost function, and gradient descent optimization.\n",
    "\n",
    "<b>Steps:</b>\n",
    "\n",
    "1- Load the California Housing Dataset:\n",
    "\n",
    "- Use the fetch_california_housing function from scikit-learn to load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the California housing dataset\n",
    "housing = fetch_california_housing()\n",
    "data, target = housing.data, housing.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 8)\n",
      "(20640,)\n",
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block group\n",
      "        - HouseAge      median house age in block group\n",
      "        - AveRooms      average number of rooms per household\n",
      "        - AveBedrms     average number of bedrooms per household\n",
      "        - Population    block group population\n",
      "        - AveOccup      average number of household members\n",
      "        - Latitude      block group latitude\n",
      "        - Longitude     block group longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n",
      "\n",
      "The target variable is the median house value for California districts,\n",
      "expressed in hundreds of thousands of dollars ($100,000).\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "A household is a group of people residing within a home. Since the average\n",
      "number of rooms and bedrooms in this dataset are provided per household, these\n",
      "columns may take surprisingly large values for block groups with few households\n",
      "and many empty houses, such as vacation resorts.\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# explore the data\n",
    "print(data.shape)\n",
    "print(target.shape)\n",
    "print(housing.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- Data Preprocessing:\n",
    "\n",
    "- Add a bias term to the input features.\n",
    "- Split the dataset into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a bias term to the input features\n",
    "data_bias = np.c_[np.ones((data.shape[0], 1)), data]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_bias, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- Standardization:\n",
    "\n",
    "- Standardize the input features using StandardScaler from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the input features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4- Linear Regression Implementation:\n",
    "\n",
    "- Implement a simple linear regression class with methods for fitting the model and making predictions.\n",
    "- Use mean squared error as the cost function.\n",
    "- Utilize gradient descent for optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression implementation from scratch\n",
    "class LinearRegression:\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000):\n",
    "        \"\"\"\n",
    "        Initialize the linear regression model.\n",
    "\n",
    "        Args:\n",
    "            learning_rate (float): learning rate.\n",
    "            n_iter (int): number of iterations.\n",
    "        \"\"\"\n",
    "        #Initialize the parameters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the linear regression model.\n",
    "\n",
    "        Args:\n",
    "            X : input features.\n",
    "            y : target values.\n",
    "        \"\"\"\n",
    "        #Initialize weights with random values\n",
    "        self.weights = np.random.randn(X.shape[1]) * 0.01\n",
    "\n",
    "        #Loop to iterate through the training program\n",
    "        for _ in range(self.n_iterations):\n",
    "            # Predict  target values (predicted_y) based on weights and input features (X) using dot product\n",
    "            predicted_y = np.dot(X, self.weights)\n",
    "\n",
    "            # Calculate the errors using difference between the predicted target values (predicted_y) and the target values we have(y)\n",
    "            errors = predicted_y - y\n",
    "\n",
    "            # Calculate the gradient of the cost function (MSE)\n",
    "            # Adjust errors based on the input relationships (transposed X) and sample size (X.shape[0])\n",
    "            gradient = (1 / X.shape[0]) * np.dot(X.T, errors)\n",
    "\n",
    "            # Update the weights by deducting the product of the learning rate and the gradient from the current weights.\n",
    "            self.weights -= self.learning_rate * gradient\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Generate predictions for X.\n",
    "\n",
    "        Args:\n",
    "            X : input features.\n",
    "        \"\"\"\n",
    "        # Generate predictions based on weights\n",
    "        return np.dot(X, self.weights)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5- Training the Model:\n",
    "\n",
    "- Instantiate the linear regression model.\n",
    "- Train the model on the training set using the implemented gradient descent algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and train the model\n",
    "model = LinearRegression(learning_rate=0.01, n_iterations=1000)\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6- Prediction and Evaluation:\n",
    "\n",
    "- Make predictions on the test set.\n",
    "- Evaluate the model's performance using mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Test Set: 4.867671375151251\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "predictions = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = np.mean((predictions - y_test)**2)\n",
    "print(f\"Mean Squared Error on Test Set: {mse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
